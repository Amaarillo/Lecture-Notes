Exam Prep - Lecture 6
---
# Survey research 
Survey research is based on doing interviews on either a simple peice of paper or a in depth interview. Survey research is as such based on indivuduals within a population. It gives a fixed, quantitative style of data collection. The purpose of this small set of question that are done a large amount of times is to be able to make generalizations surrounding the entire population. 

A survey can either be supervised = a supervisor overlooks the process, or unsupervised = sending out the questionaire over email. 

> Side note: You should never pay subjects.

Surveys can either be cross sectional = all data collected within a point of time (even thought the data collection can take days) or longitudinal = data is collected over a long period of time to notice trends and such. 

## Process 
The survey process can be split into the following phases
### 1. Formulate research questions and objectives
Formulate the purpose of the survey and the questions to be asked to the sample.
### 2-3. Identify population
Identify what people should be the population. When selecting the sample, random sampling (random.org) can be a good thing. Otherwise one can do statified sampling (splitting into stratas, i.e. subgroups). Or one can do convenience sampling (include the ones that are available and willing.) Fowled (2009) have given a good approximation of required sample size for different margins of error, and confidence levels,
### 4. Mode of data collection
How will the survey be done, mail-surveys, supervised? I.e. personal interviews, group interviews.
### 5. Constructing survey instrument
Constructing the survey questionaire. QUestions can be open or closed.
### 6. Establish reliability and validity
To be able to determine whether our results are valid and reliable we need to establish these. If the survey can be redone and get about the same distribution of replies it is reliable. Validity is how well the survey measures what we intended to measure. We can test reliablity by; test retest- test more than once. If distribution is within 0.7 it is reliable. Alternate form- randomize position of questions. Internal consistency, ask questions that measure different aspects of the same metric. When measuring validity we can measure ; ontent validity - does a group of reviewers proficient in the subject thing the questionaire is valid, Criterion validity = compare to other instruments. Construct= determine whether different data collection pproaches creates simular responses.
### 7. SURVEY INSTRUMENT EVALUATION/PRE TESTING
Two ways of testing the instrument. 
Focus group; collect group that can be seen to represent the population, run the isntrument, they determine missing questions and alike. 
Pilot groups: Do the same as main research but on smaller group.
### 8. Data analyis and interpretation. 
Analyzr the data by evaluation bias, how many answered and returned the questionaire. Check wether the ones that did not answer gives differing results (Respondent/nonrespondent analysis), Provide descriptive analyss of the data. Decide the coding for the data to be able to make statistical tests (if data is normal ordinal can be converted to numerical values.) Identify and do the statistices.